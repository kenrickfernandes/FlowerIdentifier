{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Plant_Classification_VGGA+dataaugmentationtrial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG0-QfszmtAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjcZwljPnMpi",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSHCIkconAS6",
        "colab_type": "code",
        "outputId": "2348d758-2609-49e9-e820-c36f13857a9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDv_orKZmtAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datadir = \"/content/drive/My Drive/Flowers\"\n",
        "valdir = \"/content/drive/My Drive/Flowers_valid\"\n",
        "categories = [\"Angels Trumpet\",\"Beach Moonflower\",\"Bougainvillea\",\"Cyclamen\",\"Daisy\",\"Dandelion\",\"Foxgloves\",\"Frangipani\",\"Gladiolus\",\"Hawaiian Hibiscus\",\"Nasturtium\",\"Purple Passionflower\",\"Rose\",\"Sacred Lotus\",\"Sunflower\",\"Tulip\",\"Wallflowers\"]\n",
        "img_size = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffwG27FvmtAe",
        "colab_type": "code",
        "outputId": "3404812a-96ab-4613-a26c-f5cb2ee62f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "\n",
        "from keras.applications import VGG16\n",
        "#Load the VGG model\n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGmC_0MZmtAo",
        "colab_type": "code",
        "outputId": "e4a1468a-a691-439d-d0cb-7cb7dc6b7172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# Freeze the layers except the last 4 layers\n",
        "for layer in vgg_conv.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f010c41a3c8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00bf2be390> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00bf2be240> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f00bf269b00> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00bf269438> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00bea196a0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f00bea32f60> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00bea32c18> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00be9dca90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00be982240> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f00be9a0ac8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00be9a0630> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00be94b2e8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00be961d30> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f00be90c5c0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00be90c160> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00be93e278> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f00be8cd898> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f00be8ebc18> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJnB8ZoqmtAv",
        "colab_type": "code",
        "outputId": "88d86f40-0d9a-4f63-ec46-6189d06c5e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        " \n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 6, 6, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              18875392  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 5125      \n",
            "=================================================================\n",
            "Total params: 33,595,205\n",
            "Trainable params: 25,959,941\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DdCbRLWmtA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyLyoa3CmtA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_dir = 'content/drive/My Drive/Flowers'\n",
        "validation_data_dir = '/content/drive/My Drive/Flowers_valid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKnvWW_ImtA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2, \n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCwlaUommtBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XkXew9smtBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batchsize = 100\n",
        "val_batchsize = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CNWkDLZmtBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80V0i9kBmtBg",
        "colab_type": "code",
        "outputId": "fa2c8740-14b5-4320-d33b-bb723463b376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "35/34 [==============================] - 1009s 29s/step - loss: 1.2847 - acc: 0.4993 - val_loss: 0.6040 - val_acc: 0.7764\n",
            "Epoch 2/30\n",
            "35/34 [==============================] - 49s 1s/step - loss: 0.6836 - acc: 0.7392 - val_loss: 0.9874 - val_acc: 0.7011\n",
            "Epoch 3/30\n",
            "35/34 [==============================] - 57s 2s/step - loss: 0.5907 - acc: 0.7862 - val_loss: 0.4350 - val_acc: 0.8516\n",
            "Epoch 4/30\n",
            "35/34 [==============================] - 56s 2s/step - loss: 0.4354 - acc: 0.8378 - val_loss: 0.4042 - val_acc: 0.8589\n",
            "Epoch 5/30\n",
            "35/34 [==============================] - 56s 2s/step - loss: 0.3936 - acc: 0.8573 - val_loss: 0.3652 - val_acc: 0.8767\n",
            "Epoch 6/30\n",
            "35/34 [==============================] - 55s 2s/step - loss: 0.3586 - acc: 0.8675 - val_loss: 0.3582 - val_acc: 0.8903\n",
            "Epoch 7/30\n",
            "35/34 [==============================] - 53s 2s/step - loss: 0.3187 - acc: 0.8839 - val_loss: 0.3290 - val_acc: 0.8777\n",
            "Epoch 8/30\n",
            "35/34 [==============================] - 53s 2s/step - loss: 0.2715 - acc: 0.9023 - val_loss: 0.4152 - val_acc: 0.8903\n",
            "Epoch 9/30\n",
            "35/34 [==============================] - 53s 2s/step - loss: 0.2679 - acc: 0.9100 - val_loss: 0.3130 - val_acc: 0.9080\n",
            "Epoch 10/30\n",
            "35/34 [==============================] - 52s 1s/step - loss: 0.2297 - acc: 0.9198 - val_loss: 0.3450 - val_acc: 0.9091\n",
            "Epoch 11/30\n",
            "35/34 [==============================] - 52s 1s/step - loss: 0.2183 - acc: 0.9229 - val_loss: 0.3550 - val_acc: 0.9039\n",
            "Epoch 12/30\n",
            "35/34 [==============================] - 51s 1s/step - loss: 0.1853 - acc: 0.9389 - val_loss: 0.4052 - val_acc: 0.8976\n",
            "Epoch 13/30\n",
            "35/34 [==============================] - 52s 1s/step - loss: 0.1954 - acc: 0.9325 - val_loss: 0.3960 - val_acc: 0.8642\n",
            "Epoch 14/30\n",
            "35/34 [==============================] - 52s 1s/step - loss: 0.1561 - acc: 0.9483 - val_loss: 0.4718 - val_acc: 0.8903\n",
            "Epoch 15/30\n",
            "35/34 [==============================] - 53s 2s/step - loss: 0.1724 - acc: 0.9404 - val_loss: 0.3766 - val_acc: 0.9154\n",
            "Epoch 16/30\n",
            "35/34 [==============================] - 52s 1s/step - loss: 0.1295 - acc: 0.9530 - val_loss: 0.3900 - val_acc: 0.9112\n",
            "Epoch 17/30\n",
            "35/34 [==============================] - 52s 1s/step - loss: 0.1126 - acc: 0.9618 - val_loss: 0.3879 - val_acc: 0.9101\n",
            "Epoch 18/30\n",
            "35/34 [==============================] - 56s 2s/step - loss: 0.1217 - acc: 0.9542 - val_loss: 0.3635 - val_acc: 0.8777\n",
            "Epoch 19/30\n",
            "35/34 [==============================] - 56s 2s/step - loss: 0.0956 - acc: 0.9679 - val_loss: 0.4621 - val_acc: 0.8809\n",
            "Epoch 20/30\n",
            "35/34 [==============================] - 56s 2s/step - loss: 0.1375 - acc: 0.9596 - val_loss: 0.4405 - val_acc: 0.9007\n",
            "Epoch 21/30\n",
            "35/34 [==============================] - 56s 2s/step - loss: 0.0815 - acc: 0.9741 - val_loss: 0.6162 - val_acc: 0.9028\n",
            "Epoch 22/30\n",
            "35/34 [==============================] - 55s 2s/step - loss: 0.1053 - acc: 0.9651 - val_loss: 0.4689 - val_acc: 0.9122\n",
            "Epoch 23/30\n",
            "35/34 [==============================] - 53s 2s/step - loss: 0.0821 - acc: 0.9729 - val_loss: 0.4862 - val_acc: 0.9143\n",
            "Epoch 24/30\n",
            "35/34 [==============================] - 52s 1s/step - loss: 0.1037 - acc: 0.9726 - val_loss: 0.6205 - val_acc: 0.9007\n",
            "Epoch 25/30\n",
            "35/34 [==============================] - 51s 1s/step - loss: 0.1084 - acc: 0.9724 - val_loss: 0.3893 - val_acc: 0.9039\n",
            "Epoch 26/30\n",
            "35/34 [==============================] - 51s 1s/step - loss: 0.0788 - acc: 0.9771 - val_loss: 0.5647 - val_acc: 0.9080\n",
            "Epoch 27/30\n",
            "35/34 [==============================] - 51s 1s/step - loss: 0.0819 - acc: 0.9787 - val_loss: 0.3893 - val_acc: 0.9039\n",
            "Epoch 28/30\n",
            "35/34 [==============================] - 51s 1s/step - loss: 0.0999 - acc: 0.9746 - val_loss: 0.5010 - val_acc: 0.9101\n",
            "Epoch 29/30\n",
            "35/34 [==============================] - 52s 1s/step - loss: 0.0559 - acc: 0.9827 - val_loss: 0.9072 - val_acc: 0.8966\n",
            "Epoch 30/30\n",
            "35/34 [==============================] - 51s 1s/step - loss: 0.1192 - acc: 0.9712 - val_loss: 0.6307 - val_acc: 0.9007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po8isOwz9cOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.contrib import lite\n",
        "converter = lite.TFLiteConverter.from_keras_model_file( 'model.pbs' ) # Your model's name\n",
        "converter.post_training_quantize=True\n",
        "model = converter.convert()\n",
        "file = open( 'q_model.tflite' , 'wb' ) \n",
        "file.write( model )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5IXNTGo5TIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_to_tensorflow(keras_model, output_dir, model_name,out_prefix=\"output_\", log_tensorboard=True):\n",
        "\n",
        "    if os.path.exists(output_dir) == False:\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    out_nodes = []\n",
        "\n",
        "    for i in range(len(keras_model.outputs)):\n",
        "        out_nodes.append(out_prefix + str(i + 1))\n",
        "        tf.identity(keras_model.output[i], out_prefix + str(i + 1))\n",
        "\n",
        "    sess = K.get_session()\n",
        "\n",
        "    from tensorflow.python.framework import graph_util, graph_io\n",
        "\n",
        "    init_graph = sess.graph.as_graph_def()\n",
        "\n",
        "    main_graph = graph_util.convert_variables_to_constants(sess, init_graph, out_nodes)\n",
        "\n",
        "    graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=False)\n",
        "\n",
        "    if log_tensorboard:\n",
        "        from tensorflow.python.tools import import_pb_to_tensorboard\n",
        "\n",
        "        import_pb_to_tensorboard.import_to_tensorboard(\n",
        "            os.path.join(output_dir, model_name),\n",
        "            output_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcmsybxP5Tp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras_to_tensorflow(model,output_dir=output_dir,model_name=\"saved_model.pb\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeClkoF_5T-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}